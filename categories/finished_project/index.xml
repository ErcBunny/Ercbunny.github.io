<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Finished Project on Yueqian&#39;s Page</title>
    <link>https://ercbunny.github.io/categories/finished_project/</link>
    <description>Recent content in Finished Project on Yueqian&#39;s Page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 13 Nov 2021 16:37:33 +0800</lastBuildDate><atom:link href="https://ercbunny.github.io/categories/finished_project/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Dash To Cones</title>
      <link>https://ercbunny.github.io/p/dash-to-cones/</link>
      <pubDate>Sat, 13 Nov 2021 16:37:33 +0800</pubDate>
      
      <guid>https://ercbunny.github.io/p/dash-to-cones/</guid>
      <description> VIDEO DEMO  RELATED LINKS   Source Code
  View Project Report PDF (Chinese)
   Contents of the detailed report are in Chinese as they were made originally to support the Chinese presentation. A rework and translation of illustrations, diagrams and the report is in progress, but don&amp;rsquo;t expect it to be finished soon. Best regards~
 </description>
    </item>
    
    <item>
      <title>HLJenga: Hexalink Jenga Manipulator</title>
      <link>https://ercbunny.github.io/p/hljenga-hexalink-jenga-manipulator/</link>
      <pubDate>Thu, 01 Jul 2021 15:24:52 +0800</pubDate>
      
      <guid>https://ercbunny.github.io/p/hljenga-hexalink-jenga-manipulator/</guid>
      <description>VIDEO DEMO  OVERVIEW  We were required to program QKM manipulators to play Jenga automatically My part was doing hand-eye calibration, blob analysis, path/trajectory planning and simple UI The robot operates like this:  Take a picture with camera and calculate target positions Do path and trajectory planning Upload planned trajectory to bot Run     HAND-EYE CALIBRATION HEC Explained in A Nutshell  Aims to find the transform matrix from camera frame to tool frame.</description>
    </item>
    
    <item>
      <title>Autonomous Delivery Drone</title>
      <link>https://ercbunny.github.io/p/autonomous-delivery-drone/</link>
      <pubDate>Fri, 23 Apr 2021 14:55:42 +0800</pubDate>
      
      <guid>https://ercbunny.github.io/p/autonomous-delivery-drone/</guid>
      <description>VIDEO DEMO  PROJECT OVERVIEW   Nothing interesting or related to cutting-edge research. Just an engineering level practice
  Some technical approaches:
 Localization: optical flow, TOF sensor Detection and navigation: YOLO + KCF + Hough Circle Transform on TX2 Flight controller: ACFLY ADRC Communication between FC and TX2: velocity command through serial UART     DETAILED REPORT   View Control and Electronic Circuit Design Scheme PDF (Chinese)</description>
    </item>
    
    <item>
      <title>A 3-Rotor VTOL UAV</title>
      <link>https://ercbunny.github.io/p/a-3-rotor-vtol-uav/</link>
      <pubDate>Thu, 15 Aug 2019 13:20:21 +0800</pubDate>
      
      <guid>https://ercbunny.github.io/p/a-3-rotor-vtol-uav/</guid>
      <description>VIDEO DEMO  SYSTEM OVERVIEW   VTOL is achieved by adding a mixing unit to the F4 flight controller running Betaflight Y3 firmware
  The mixing unit takes in PWM outputs of a basic multicopter flight controller and yields signals for VTOL actuators
  We only implemented attitude control. Communication between boards is via PWM
   Illustration of the UAV | ①: Aileron, ②: Rudder &amp;amp; Elevator, ③ &amp;amp; ④: Tilt Servo, ⑤: Motor</description>
    </item>
    
    <item>
      <title>BunnyAAT</title>
      <link>https://ercbunny.github.io/p/bunnyaat/</link>
      <pubDate>Fri, 14 Sep 2018 10:19:16 +0800</pubDate>
      
      <guid>https://ercbunny.github.io/p/bunnyaat/</guid>
      <description> VIDEO DEMO  DESIGN  Please refer to the related links   RELATED LINKS  百度贴吧 Source Code  </description>
    </item>
    
  </channel>
</rss>
