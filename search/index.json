[{"content":" LINKS  Presentation of Previous Work (English) Research Proposal (Chinese) Midterm Summary (Chinese)   VIDEO DEMO \r\r Dev Milestones  [Dec 01 2021] Upgrade to ROS2: 100% [Dec 15 2021] PID and Newton-Euler Dynamics in SITL: 100% [Dec 31 2021] Real hardware drivers and maiden flight: 100% [Mar 01 2022] Adaptive MPC real flight: 20%  controller architecture and design: 100% formulate MPC solver using acados: 100% test MPC solver in Python: 5% MPC node: 5% L1 adaptive enhancement: 0%   [Apr 01 2022] Track trajectories and collect data: 0% [May 01 2022] Thesis writing: 0%  Environment Setup  Ubuntu 20.04 LTS with ROS2 foxy and ROS1 noetic (since vrpn-client-ros is only available for ROS1). Install ROS2 via debian and additional tools. Install Fast-RTPS-Gen using source code.  Install Gradle v6.3 through sdkman. Use Gradle to build and install Fast-RTPS-Gen.    git clone --recursive https://github.com/eProsima/Fast-DDS-Gen.git -b v1.0.4 ~/Fast-RTPS-Gen \\ \u0026amp;\u0026amp; cd ~/Fast-RTPS-Gen \\ \u0026amp;\u0026amp; gradle assemble \\ \u0026amp;\u0026amp; sudo env \u0026#34;PATH=$PATH\u0026#34; gradle install Install dependencies for PX4: PX4-Autopilot/Tools/setup/ubuntu.sh. Install officially provided ROS2 plug-ins for Gazebo: sudo apt install ros-foxy-gazebo-ros-pkgs. Install QgroundControl ground station. Install packages for optitrack: sudo apt install ros-foxy-ros1-bridge ros-noetic-vrpn ros-noetic-vrpn-client-ros  vrpn-client-ros publishes the built in message type geometry-msgs, it is OK to use debian release of ros1-bridge. Building ros1-bridge form source enables extra support for custom message and service types but has conflicts with ros-foxy-controller-manager-msgs.   Install mavros for data visualization: sudo apt install ros-noetic-mavros* ros-noetic-mavlink.  Usage Simulation with Gazebo  Build ROS2 workspace.  source /opt/ros/foxy/setup.bash cd scripts ./build_all_ros_clean.sh Build and run PX4 SITL simulation. It is required to source ROS2 setup file.  source /opt/ros/foxy/setup.bash source ./ros2-workspace/install/setup.bash cd PX4-Autopilot PX4_NO_FOLLOW_MODE=1 px4_sitl_ctrlalloc gazebo_omni_hex Run micrortps_agent over UDP.  source /opt/ros/foxy/setup.bash source ./ros2-workspace/install/setup.bash micrortps_agent -t UDP Use QGC to give commands to the simulation environment. Several useful buttons and modes are listed below.  Takeoff and land Virtual joysticks Position mode, altitude mode, ACRO mode   Or use the offboard control node to generate a trajectory for omniHex to track.  source /opt/ros/foxy/setup.bash source ./ros2-workspace/install/setup.bash ros2 run px4_ros_com offboard_control  Above mentioned steps are implemented in run_simulation.sh, run this script, take off to {0, 0, 2.5} and run offboard.sh to track the 8-shape trajectory.\n Real World Flight   Port connections on NUC:\n dynamixel servos on /dev/ttyUSB0 @ 115200 urtps_bridge on /dev/ttyUSB1 @ 3000000 -\u0026gt; MCU TELEM1 QGC/mavlink on /dev/ttyACM0 @ any baud (ACM1 occurs after a reboot) -\u0026gt; MCU microUSB    About RC:\n switch A is the kill switch switch F sets different flight modes (up: altitude, mid: position, down: acro).     Setup the motion capture system.  Open motive software and open the most recent project (Z-up configuration). Go to capture layout (upper-right corner) and delete default rigid bodies. Aligned markers with the world frame and create a new rigid body from the selected ones, rename this new instance to uav (as it is fixed in ros1-workspace/src/vrpn_client/launch/default.launch). Data is automatically published to local network.   Build PX4 firmware.  source /opt/ros/foxy/setup.bash cd PX4-Autopilot make cubepilot_cubeorange_ctrlalloc Upload firmware to MCU.  Open QGC and navigate to \u0026ldquo;Vehicle Setup-Firmware\u0026rdquo;. Plug in MCU through USB (ttyACM) port and QGC will auto detect the MCU. This step requires the MCU only powered by USB. Select custom firmware and upload PX4-Autopilot/build/cubepilot_cubeorange_ctrlalloc/cubepilot_cubeorange_ctrlalloc.px4. Restart QGC so that airframe files could be loaded by QGC, then you can do further settings and calibration.   Build ROS1 workspace.  source /opt/ros/noetic/setup.bash cd ros1-workspace catkin build Build ROS2 workspace.  source /opt/ros/foxy/setup.bash cd scripts ./build_all_ros_clean.sh Start packages on NUC: setup_real_flight.sh. This script starts the following necessary drivers.  ROS1 vrpn_client ROS2 ros1_bridge ROS2 micrortps_bridge, dyanmixel_driver, optitrack   Now you can use packages like rqt or rviz for data monitor and visualization. Make sure to source the corresponding ROS version and workspace.  Software Version  The original version of PX4 is stable release v1.12.3. Modified submodules derive from the commit that is referenced by PX4. The original version of px4_msg is commit 0f550f436547fccc6b86d448e095ad914f5de94a on master branch. px4_ros_com: commit c618d757bd64113ccbee17ad0ae17ab8122337e8 on master branch.  Coordinate Frame  SDF and Solidworks models  front-x, left-y, up-z (body)   PX4  NED (world) front-x, right-y, down-z (body)   Gazebo  N-Green-y, E-Red-x, U-Blue-z (world)   Arm rotation: see Control Allocation of a Tilting Rotor Hexacopter In SITL, PX4 NED x is aligned with Gazebo y In lab setting, PX4 FRD is algined with optitrack x  SW Model to SDF  There are several useful links  Gazebo official guide Format standard of .sdf   Do NOT use SW2018SP0 Minimize the number of links. It is good to treat parts that do not move relatively as a whole. Only separate parts into links if there must be a joint in between. Usually, a link corresponds to an assembly. In the assembly that represents a link, make sure to attach a coordinate frame in the SDF convention to the model. This frame will be used as the reference frame when exporting .stl and calculating mass properties. When exporting to .stl files, hide fine parts otherwise your file would be too big. Choose the aforementioned reference frame, use meter as the scale, and select \u0026ldquo;do not transform to positive space\u0026rdquo;. Write the SDF  SDF uses kilogram and meter as the default unit. Don\u0026rsquo;t use mesh as collision. Use the geometry shapes instead. Specify a min_depth property to the collision that is in contact with the ground. Use numbers in \u0026ldquo;Moments of inertia, taken at the center of mass and aligned with the output coordinate system\u0026rdquo;. Numbers that are not on the diagonal line of the matrix should be inverted.   sitl_gazebo plug-ins: \u0026ldquo;IMU\u0026rdquo; should be loaded after \u0026ldquo;mavlink interface\u0026rdquo;.  ROS1 Packages mavros_client  An overlay package for customizing the launch file. Note that this package should not be named mavros, otherwise ROS may not find the right package path.  vrpn_client  An overlay package for customizing the launch file.  ROS2 Packages custom_gazebo_plugins  This package is a supplement to officially provided ROS2 plug-ins and those provided in PX4-Autopilot/Tool/sitl_gazebo. The official repository provides example code for writing a plug-in. gazebo_ros_arm_rotation.cpp is for controlling the position of six arm joints of omniHex via the PID API. Similarly, gazebo_ros_joint_pid_ctrl.cpp controls the position of a single joint via PID. gazebo_ros_joint_motor.cpp is for controlling joint position or velocity via SetParam and SetPosition API. gazebo_ros_motor_model.cpp is a simplified ROS2 adaptation of the original version in PX4-Autopilot/Tool/sitl_gazebo.  px4_msgs  This package contains message types needed by px4_ros_com and other packages that might use the PX4 types, as well as rqt utility. The msg folder is updated by the script in PX4-Autopilot/msg/tools/uorb_to_ros_msgs.py. It should be synced whenever a message definition in PX4-Autopilot/msg is changed.  px4_ros_com   The main purpose of this package is to generate the communication bridge micrortps_agent from a template file src/templates/uorb_rtps_message_ids.yaml. The template file should be synced with PX4 via script PX4-Autopilot/msg/tools/uorb_to_ros_rtps_ids.yaml.\n  There is also an example of off-board control available in src/examples/offboard. This example code is modified to generate a full position-pose trajectory as the function of timestamps.\n circle 8-shape   TODO: use input args or launch file to specify trajectory shape\n   It also provides useful scripts for cleaning and building the workspace.\n Previously, build_ros2_workspace.bash is set to skip custom_gazebo_plugins because the latter depend on px4_msgs. It is better to add \u0026lt;depend\u0026gt;px4_msg\u0026lt;/depend\u0026gt; in package.xml. In this way we don\u0026rsquo;t need to specify a order. Make sure to add find_package(px4_msgs REQUIRED) and ament_target_dependencies(foo ...px4_msgs...) in CMakeLists.txt.    optitrack_driver  visual_odom_publisher receives pose data from MOCAP, performs frame transformation and publishes data to topic VehicleVisualOdometry_PubSubTopic. In this target, the message is published in a timer callback at 50Hz. Timestamps are taken from VehicleImu_PubSubTopic. callback_relay is a simple relay. It is similar to visual_odom_publisher but instead of publishing data in a timer callback, it publishes data in the callback for receiving pose data.  dynamixel_driver  read_write_node is the example node provided by dynamixel_sdk. arm_position_control is the one used for controlling the arm positions. It communicates with dynamixel servos via UART in the callback function for receiving ArmRotation_PubSubTopic.  trajectory_generator  A package for generating trajectories in MPC framework and visualizing TrajectorySetpoint_PubSubTopic. Visualization is implemented in rviz_translator.cpp  PX4 Tools and Miscellaneous  Set the correct URL in .gitmodules. Custom models for Gazebo simulation is put in PX4-Autopilot/Tools/sitl_gazebo/models with a corresponding .world file in PX4-Autopilot/Tools/sitl_gazebo/worlds.  The initial condition of the simulation could be set in PX4-Autopilot/Tools/sitl_run.sh. Some plug-ins are built externally (in the ROS2 workspace). So PX4-Autopilot/Tools/setup_gazebo.bash is modified to export the correct library paths.   As we are using the micrortps_bridge, we need to build this module in PX4. We can specify this feature by uncommenting the micrortps_bridge line in PX4-Autopilot/boards/px4/sitl/ctrlalloc.cmake, which is the module configuration file for SITL targets. We can choose what modules to be built and what not to be built. The same rule applies to .cmake files for other boards. Add our custom model for gazebo simulation in PX4-Autopilot/platforms/posix/cmake/sitl_target.cmake. Add our airframe file (a model-dependent script for loading parameters and modules) for simulation in PX4-Autopilot/ROMFS/init.d-posix/airframes and make sure to add this file to the CMakeLists.txt. The airframe for real hardware is init.d/airframes/6004_omni_hex. A new mixer is in use: omnihex.main.mix. mc_rate_control isn\u0026rsquo;t started in rc.mc_apps if MIXER = omnihex  PX4 Messages  Add a message to hold arm positions and limit status: arm_rotation.msg. After adding a new message file, don\u0026rsquo;t forget to indicate it in CmakeList.txt, otherwise it won\u0026rsquo;t be compiled. Every message should be assigned an ID in msg/tools/urob_rtps_message_ids.yaml or targets with micrortps_bridge enabled cannot be compiled. Also, we can specify how micrortps_bridge treat each message. vehicle_attitude_setpoint.msg and vehicle_local_position_setpoint.msg are modified to handle roll and pitch movements.  PX4 Modules  Generally, a good way to read the code is to look at the header files first. Look at topic subscriptions and publications. Then look at the run() function in .cpp files. Modified modules are angular_velocity_controller, commander, control_allocator, flight_mode_manager, mc_att_control and mc_pos_control.  angular_velocity_controller   Center of mass compensation $x_{com} \\cross F_{sp}$ in AngularVelocityControl.cpp/hpp, void AngularVelocityControl::update().\n  Read center of mass parameters and call AngularVelocityControl::update() with additional arguments inAngularVelocityController.cpp/hpp.\n  Newton-Euler equation cross term $\\omega_b \\cross v_b$ in void AngularVelocityController::Run().\n  Center of mass parameters are defined in vehicle_model_params.c.\n  commander  In void Commander::update_control_mode(), ACRO mode is added with the same set of configuration as POSCTL mode.  control_allocator  The allocation matrix (actuator effectiveness) is implemented as a subclass of ControlAllocationPseudoInverse and ModuleParams. See ActuatorEffectivenessOmniHex.cpp/hpp/params.c for more detail. In PX4 convention, torque comes above force in a wrench. Add omniHex to enum classes, switch cases, and includes in ControlAllocator.cpp/hpp. Publish control signals to actuator_controls_0 instead of actuator_controls_4, with actuator_controls_0[3] reserved for total thrust signal. Always check CMakeLists.txt  flight_mode_manager   This module takes care of controller setpoints in different flight modes.\n  Switch to FlightTaskIndex::ManualAcceleration when in vehicle_status_s::NAVIGATION_STATE_ACRO. This feature is implemented in FlightModeManager.cpp.\n TODO: exclusive flight task for ACRO mode (not only pitch but full pose)\n   FlightTask.cpp/hpp: add missing variables and functions that are not implemented for roll and pitch commands.\n  FlightTaskManualAltitude.hpp: add scaling factors from stick to roll and pitch rate.\n  FlightTaskManualAcceleration.cpp/hpp: generate different setpoints in different navigation states.\n  Set roll pitch angle and angular speed setpoint in FlightTaskFoo::activate() function of tasks such as Auto, Failsafe and ManualAltitudeSmoothVel. This is necessary because otherwise the vehicle loses roll and pitch control when auto buttons in QGC is pressed.\n  mc_att_control  AttitudeControl.cpp: matrix::Vector3f AttitudeControl::update() is modified to consider turning rate feed-forward. AttitudeControl.hpp: add roll and pitch in void setAttitudeSetpoint(), also variables. mc_att_control_main.cpp and mc_att_control.hpp: call modified function with the right arguments.  mc_pos_control  PositionControl.cpp/hpp: add variables to take care of roll and pitch rotation. In void PositionControl::getAttitudeSetpoint() attitude setpoints are passed down and thrust setpoint is converted into body frame. mc_pos_control_params.c: define parameters for manual roll and pitch rate control, which are used in FlightTaskManualAltitude.hpp. MulticopterPositionControl.cpp/hpp: call modified functions and pass correct arguments.  EKF2  In PublishAttitude, an extra step of converting and publishing RPY is added.  mixer \u0026amp; px4io   AllocatedActuatorMixer.cpp now listens to actuator_controls_0 instead of actuator_controls_4.\n  ESC calibration parts in px4io.cpp and mixer_module.cpp are modified for control[0] to control[6], except control[3].\n TODO: test calibration function, make sure props are removed\n   Motor-Propeller Model SITL  In gazebo_motor_model and omni_hex.sdf  motorConstant = thrustCoef = 8.5e-06 torqueCoef = thrustCoef * momentConstant = 8.5e-06 * 0.06   In px4  The thrust coefficient if defined as Thrust = CT * u^2, where u (with value between CA_ACT0_MIN and CA_ACT0_MAX) is the output signal sent to the motor controller. CT = 19.125 The moment coefficient is defined as Torque = KM * Thrust (is consistent with momentConstant). KM = 0.06   From u (PX4) to $\\omega$(real rotor angular velocity)  PWM = 1000 * (1 + u) (observation from print-debugging), where u = actuator_setpoint[0, 1] omega = (u + offset) * scaling + idle @(line ~1121 mavlink interface plugin), in sdf offset = 0; scaling = 1500; idle = 100   Conversion between CT(PX4) and motor constant (thrust coef, paper, plugin), we assume that the idle value is negligable  CT = scaling^2 * motorConstant    Real World Data  TODO: mapping between PWM and angular velocity, determine thrust and torque coefficient\n  x = actuator_setpoint[0, 1] to y = actuator_controls_0[-1, 1]: $y=2x-1$ x = actuator_controls_0[-1, 1] to y = PWM[min, max]: $y=\\frac{x(y_{max}-y_{min})}{2}+\\frac{y_{max}+y_{min}}{2}$ x = PWM[min, max] \u0026amp; y = relative_thrust[0, 1]: $ay^2+(1-a)y-x=0$, where $a\\in[0.25,0.35]$  Matlab Files  In matlab-workspace. trajectory.m: visualization of 8-shape trajectory.  ","date":"2022-03-27T16:37:33+08:00","image":"https://ercbunny.github.io/p/omnihex/cover_huf54f83ec7f48f4593ffcb0ac862986d3_1368328_120x120_fill_box_smart1_3.png","permalink":"https://ercbunny.github.io/p/omnihex/","title":"OmniHex"},{"content":" 前言  \n看着之前的年度总结，不经感叹我以前真的好认真啊，现在就貌似已经开摆了，只能靠翻相册来回忆这一年发生了什么事情这个样子（哭）。\n不过也很有趣啦，回顾照片什么的，能找回当初拍摄每一张照片的心动的感觉。\n总之就是篇post就是这一年的点点滴滴啦～看起貌似真的啥也没干哦……\n不对，应该说是忙得很充实，见证了许多美景，遇见了许多有意思的伙伴。\n新的一年希望还是能够拿到Offer啦，然后……然后无限进步！😆PEACE～（若有图片涉及肖像权问题，侵删～）\n January  上自控实践的实验课部分，手机里存了好多多多多试验设备照片啊啊啊啊 完成了pyTimelapse，我愿称之为好活 在T3实验室弄工训无人机，当时的心态是抱着拿国奖加分去的，后面的结局证明年轻人做事情还是不要太功利 上一年的年度总结，妈耶写的好详细，给跪了     \n   \n February  收到了人生第一台Macbook，结果脚垫竟然不平，后面去天环广场给换了，M1确实续航强无敌，果子的入门级移动设备果然不会让人失望 一家人去了趟宝墨园，踏春，好看～ 放假跟着去南沙网球基地试了红土地，放了烟花，好多好视频放不上来，也懒得传B站了（是啊我怎么这么懒啊 回学校赶上发烧还小题大做上报去深大医院做核酸，mdzz，就是脑袋一热想要给疫情防控做贡献的感觉？ 开始了自控B的学习，手机里拍照图一堆一堆的（现在看也是完全看不懂了哈哈哈呜呜呜😭），再次怀念ZY老师的自控A的讲稿     \n     \n March  开始了电工实习，机器人导论，以及一堆课（evidence by screenshots and slide photos） 发现麦当劳的早餐薯饼夹入吃法，好评 XMQ加入了我和CLX的Workout计划，但也就坚持了一两周 考了TOEFL，考完被晾在考场自生自灭，途中看到了撸猫猫大队 开始了omniHex项目，现在回想起来真的走了好多弯路，不说了，都是泪     \n   \n April  四月的一开头就是KTV黑照暴击(雷宝哈哈哈) 工训赛校内测试时候以为稳了，结果惨不忍睹，失败点在于图像识别算法对光照条件变化的鲁棒性太差 院羽毛球赛开打～轻羽飞扬（bushi       \n \n May  电工实习终于结束了，用MSP430撸了一个智能（zz）电扇，以后应该再也不会去碰这玩意儿了 从此也是ROG公民了，当时R9000p没货，反手就入了ROG，逼上梁山了属于是 学校羽毛球比赛结束，亚军，好耶😄 这个月景色很好，真的绝绝子！！！       \n   \n \n June  四食堂开了，当时的小炒yyds，后面就真的再没吃到过第一次去的味道了，怎么说，四食堂有种有恃无恐的感觉…… 肝完了机器人导论课设，HLJenga Rules! 在G305摸了一块地方作为办公位置，赶上了科创学院的剧组拍摄宣传片，呵呵呵呵呵还以为能见到Prof. Shaojie Shen呢，看来是想多了 是不是感觉这个月平平无奇，嗯，因为在肝omniHex，走弯路中     \n   \n July  给笔记本清灰换内存，32G内存拉满 从WHL嫖来了米哈游的夏日零食箱，谢谢导师（游戏内master）～虽然只有箱子 omniHex实现了位置和姿态的解耦控制 回GZ和高中宿舍小伙伴小聚，毕竟放假嘛呵呵呵 买了个蒂蒂抱枕，为斯卡蒂献上心脏！！！         \n \n August  omniHex实体机器人完成组装，过程真的很累，迂回前进，以至于不想过多描述 开始投学校了，面了港大两个弄机器人的实验室，MARS不要我，ARCLAB让我做RA；对比同期RYF学长已经可以直接拿口头offer了，看来我是个FW   \n   \n \n September  去了一趟CUHKSZ，好玩，见到了好多老同学，同学们都好优秀啊啊啊 社团招新，终于有点SS那味道了，随后加入了合唱团 拍了毕业证上的照片，可惜当时不会打理头发，所以效果不行，只能说还凑合 pyTimelapse手机电池鼓包了呜呜呜，移到了室内 吹爆CSY老师的Media \u0026amp; Culture课，真的好棒，而且给了我真正表达自己、练习口语的机会。感觉其他同学都有点小害羞不知道为啥，可能是准备run了，在这个学校已经没有在意的人了叭 以摸鱼的速度开始准备GRE，后面果然寄了   \n     \n \n October  从集市上得知一食堂的肠粉，广东人泪目 考了一次GRE沉了，痛定思痛开始准备二战 到隔壁清华参加他们的某个晚会，感叹不愧是清华，当时这么酸，但是后来发现工大后来的其实也不差嘛哈哈哈（就是说人总是一边受着母校的照护，享受着光环的加护，又一边骂她哪里哪里不好，当然内心里却是真心希望她能变的更好这样子）     \n \n November  通过了一个EPROP-HKUST的联合培养项目，去那边看了下，受到了热情招待，但是最后感觉条件有点限制就算了（如果真的去了我现在基本就躺平了，导师随便挑，港科大PHD手到擒来。不过接下来接近一个decade的人生轨迹也大致确定了，一这么想就觉得有点可怕） 看到了金星伴月（大概？），当时好多人在路上拍，我和LX刚好跑完步，感叹真的很漂亮 重做了精细版本的omniHex仿真模型，都是泪啊 合唱团第一首曲目大概排出来了Ave Maria～LHX sensei yyds 完成了DIP课程设计     \n \n \n   \n December  去艺术团摸鱼的时间增多了，练声，玩阿卡贝拉，混入彩排 各种课结课了，我免费（free）了哇哈哈哈哈 投递了各种申请，海了9所，遍布北美，欧陆，南亚，远东……希望有人要我，求求了…… 控制杯羽毛球二轮游（就当是参与实验室团建拍照了 GRE上岸后去看运动会，当时是一个春风得意啊，就差一日看尽长安花了 个人网站上线，感谢GitHub Page服务，感谢Jimmy的Theme 寿喜锅自助，然后从深圳湾沿河边骑车回来，感谢同行HXD的陪伴，是今年做的为数不多的让人感觉“我还年轻”的事情 游园会，好多好有意思的，就是高级版社团节，还上去舞台唱了歌儿，但是车祸现场……嗯看来确实得认真学几首歌能一下子拿的出手的歌啊（之后集市上有好多表白XGG的，为什么没有我💔，我是FW） 终于参加了一次元旦晚会，但是是上去混的哈哈哈哈，艺术团的小伙伴们好好玩，谢谢你们，让我能够完成“登上元旦晚会舞台”的TODO list       \n   \n   \n","date":"2021-12-31T14:50:23+08:00","image":"https://ercbunny.github.io/p/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/2021_huc3104e52fb0cb68d4eefc17c54b3614e_1481937_120x120_fill_q75_box_smart1.jpg","permalink":"https://ercbunny.github.io/p/2021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","title":"2021年度总结"},{"content":" 篇幅较长，请先浏览目录，方便导航哦～\n  2021年12.31考试内容  机器人的自由度计算 轮子的自由度 sobel算子作用 直线检测各种算法原理 搜索算法哪个完备 概率框架下的定位模型 什么噪声没办法去除 dijkstra markov定位图 split merge 势场法导航 卡尔曼滤波的k矩阵 单轮驱动的运动模型，自由度 odom模型和误差传播   绪论 按功能分类  移动机器人 操作机器人 移动作业机器人 举些例子：机械臂，月球车，心脏手术，扫地，UAV，自驾车  应用领域  工业 空间探测 军事 医疗手术 家庭  自动化  自主性(autonomy)是行为主体按自己意愿行事的动机、能力或特性  自主移动机器人是一类可以根据任务需求、具有在单维或多维空间主动改变自身位姿以及空间位置能力的机器人统称 自动驾驶分级：0-2级需要驾驶员实时介入，自动驾驶提供辅助速度和车道控制；3级有时会要求接管驾驶，4级开始是在特定环境下完全自主，5级是所有环境下全自主  0-2：特斯拉，小鹏，未来 没有一个达到了3     三大关键问题：在哪，去哪，怎么去 经典3环节  see (perception): sensing, info extraction (filtering, keypoint extraction and matching) think (planning/understanding): localizatoon, mapping, planning act (motion control): tracking, actuator driving     general pipeline \n 运动形式 运动相关的概念  locomotion，运动，是一种机器人与环境的物理交互 稳定性考虑：接触点数目和形状（角度，摩擦），重心，环境（地形，空气），本体稳定性  两种地面运动形式  腿式运动  自然界偏爱，自然界表面粗糙，环境复杂 通过性强，控制困难，非连续点接触 效率取决于本体质量 近似滚动多边形，随着步距减小，接近圆形   轮式运动  自然界基本没有，因为关节不能旋转 在平面上运动效率高，控制简单，受环境约束大 效率取决于环境质量    腿式机器人  特点（因为不同场景下优点和弱点互相转换）包括：适应地形，自主调节重心高度，运动执行器也能当成操作器，主动隔离震动，自由度高，难控制建模，对关节驱动要求高，需要配合地形感知，落地有冲击 稳定性  动态稳定指的是执行器停止工作时机器人摔倒，反之则是静态稳定的 静止时保持稳定的条件  点接触腿需要三支同时着地（波士顿动力方案，快，动态稳定，能耗低） 面接触腿只需要一支（比如日本方案的双足，静态稳定，慢，能耗高）   运动时保持稳定的条件  静态步态行走需要4-6条腿     关节数和自由度：每个腿至少需要两个自由度，增加自由度可以提高机动性、步态稳定性，同时增加设计难度 可能事件总数Gait/步态：一个行进周期内腿式机器人每条腿抬起和落地可能性的组合$=(2k-1)!$注意与腿状态数区分 $=2^k$  轮式机器人  特点：人造结构的高效性（滚动摩擦，重心不会起伏变化），结构简单，成本低，控制简单，系统复杂度低，运行速度高 稳定性：至少有三个车轮同时接触地面才能保证静态稳定性（重心落在接触点的三角形内部），3个轮子以上需要悬挂系统使所有轮子保持与地面接触 轮子类型  标准轮，DOF=2 脚轮，DOF=3，调向时会对机器人底盘施加一个扭矩，偏心距d:触地点到垂直旋转轴的距离 瑞典轮（十字连续切换90/麦克纳姆45），DOF=3，无法单独使用，至少需三个或以上共同使用，对地面冲击大，噪音大，易破坏地面，运行震动大，对机器人本体机构冲击大 球轮，DOF=3，无约束:具有很高的灵活性，成本高:制造和维护成本均很高，积灰、磨损   全向驱动经典布局：等边三角形，瑞典轮，转向标准轮，4麦克纳姆   轮式机器人运动学 非完整约束  大部分轮式机器人形态均含有非完整约束，即无法从位置空间找到一一对应的关系，和历史状态有关 需要扩展到速度空间 (车轮间相对位置增量的差别)考虑微分运动学  坐标系描述  惯性参考坐标系 $\\xi_I$ ：机器人作业目标及控制指令，传感器感知测量的环境信息 机器人参考坐标系 $\\xi_R$ ：机器人控制器的误差输入以及控制指令 config矩阵可以是 $3 \\times 3$ ：因为只有两个维度 $\\bold{\\dot{\\xi_I}=R(\\theta)\\dot{\\xi_R}}$ ，两个坐标系下的速度之间关系为旋转矩阵   坐标系的一般设置 \n(前向)运动学模型  指建立惯性系下参考点速度和执行器速度之间的关系 中间桥梁为机器人系下参考点速度 构建方法  作用法：从轮运动参数（转速，半径，轮距），进行速度的合成与分解（同时考虑约束作用），得到参考点在机体坐标系下的速度，然后通过旋转矩阵转为世界坐标系 约束法：把每个轮子的约束方程写出来（轮运动参数与机体坐标下速度的关系），合并成一个式子并转换为世界坐标速度   标准轮约束  主动固定标准轮：$v_{\\parallel}=r \\dot{\\phi}$ 以及 $v_{\\perp}=0$ ；将 $v_{\\parallel}$ 和 $v_{\\perp}$ 用机体坐标系下的速度表示出来 主动转向标准轮：滚动约束，可控制角度来改变运动： $v_{\\parallel}=r \\dot{\\phi}$ 随动固定标准轮：无侧滑约束（滑动约束）： $v_{\\perp}=0$ 随动转向标准轮：自由   脚轮约束  作为主动轮：滚动约束，可控制角度来改变运动 作为从动轮：自由   球轮约束  主动：与主动转向标准轮一致 从动：自由   瑞典轮约束  主动：驱动速度 $\\dot{\\phi} r$ 往转子上投影作为最终这个执行器产生的速度，没有无侧滑约束  记 $\\gamma$ 为滚子轴与轮平面的夹角，则滚动约束为 $\\dot{\\phi} r \\cos(\\gamma)=v_{\\parallel}$ ，这里 $v_{\\parallel}$ 指的是机体坐标系下速度滚子轴方向的投影   从动：自由   零运动直线：几何上经过轮子的轴心并垂直于轮平面的线，当受无侧滑约束时，轮子在该直线上不能存在运动  脚轮、瑞典轮：不存在无侧滑约束，不存在零运动直线   轮式移动机器人运动学建模仅考虑平面运动，因此其对应的输出状态为三维向量，因此，最多有三个独立约束 动力学建模在运动变化较为快速、动态响应比较明显的情况下适用，比如无人机上   运动学模型例子 \n自由度  自由度是机动性的度量 总自由度=移动mobility自由度+操纵steerability自由度：$\\delta_{M}=\\delta_{m}+\\delta_{s}$  $\\delta_{M}=3$：瞬心可在平面的任意点，可在工作空间中跟踪任何路径 $\\delta_{M}=2$：瞬心被限制在某条直线上   移动自由度（可移动度）$\\delta_{m}$  $\\delta_{m}=$ 工作空间维度 $-$ 独立约束数目 $=$ 状态向量的维度 $-$ 滑动约束中的独立约束个数 考虑 $\\bold{AR\\dot{\\xi_I}} = [\\bold{B,0}]^T$ 这样动力学模型的基本形式，与 $\\bold{0}$ 对应的 $\\bold{A}$ 的部分子矩阵零空间维度 $=$ 列数 $-$ 秩 $=\\delta_{m}$ $\\delta_{m}=0$ 时无法在平面中运动， $\\delta_{m}=1$ 时只能沿着圆弧/直线行走（移动性退化）， $\\delta_{m}=2$ 时可原地（线速度和角速度解耦）， $\\delta_{m}=3$ 时全向  二轮差速小车：通过改变轮转速可同时控制角速度和线速度， $\\delta_{m}=2$ 自行车：改变主动轮转速只能改变线速度，角速度要通过另一个轮子的方向， $\\delta_{m}=1$     操纵自由度（可操纵度） $\\delta_{s}$  等于独立的能够转向的舵机的个数，范围是 $[0,2]$ 考虑 $\\bold{A}$ 矩阵中滑动约束部分，挑出其中转向轮的子矩阵，求秩，则等于 $\\delta_{s}$   机器人的完整性判据：可移动度等于工作空间维度  对于地面移动机器人，工作空间维度是3     自由度计算例子 \n 二轮差速机器人的控制  只考虑运动学控制，仅分析二轮差速小车\n 术语和零碎知识点  定点(镇定)控制Regulation Control：以指定姿态到达指定工作位置 路径跟踪控制Path Tracking Control：跟随给定路线 轨迹跟踪控制Trajectory Tracking Control：跟随给定的轨迹 对于非完整约束机器人而言，不存在静态反馈控制律，使得机器人达到目标位姿 移动机器人反馈控制器设计一般步骤  根据作业需求定义系统开环误差信号 误差信号描述变换:惯性参考坐标系、机器人参考坐标系 基于机器人模型，构建闭环系统误差模型 控制器设计 稳定性分析 仿真实验 实际实验   自治系统(Autonomous system)：控制量只依赖状态不依赖时间 微分平坦(differentially flat)系统：控制量可以用状态量及其导数来表示 非完整约束系统总是欠驱动系统 可控：能通过施加控制使系统到达状态空间中的任意一个状态，是模型本身的性质，与控制量无关 系统存在光滑的反馈控制的必要条件，Brockett定理  定点控制  机器人模型 \n 记号和问题描述  $q=[x,y,\\theta]^T$ 为世界坐标系下的状态 $q_r=[x_r,y_r,\\theta_r]^T$ 为世界坐标系下参考状态 $\\tilde{q}=[\\tilde{x},\\tilde{y},\\tilde{\\theta}]^T=q-q_r$ 为开环误差 $e=\\bold{R(\\theta)^T} \\tilde{q}$ 为机体坐标系下误差信号 误差的动态模型是 $\\dot{e}$ 使用“左导右不导……”可展开，矩阵求导这里是每个元素分别求导即可 定点控制是找到一系列 $\\bold{\\dot{\\xi_R}} = [v(t),\\omega(t)]^T = [\\dot{x}(t), \\dot{y}(t), \\omega(t)]^T = \\bold{K}e$ 使 $e(t)=0$， 这里 $\\bold{K}$ 为控制矩阵，是要设计的变量， $\\bold{\\dot{\\xi_R}}$ 则能通过运动学模型转化为执行器需要的输出 这个模型中 $\\dot{y}(t)=0$ ， $\\dot{x}(t)=v(t)$   惯性坐标系中机器人的运动学模型  $\\bold{\\dot{\\xi_I}} = \\bold{R(\\theta)\\bold{\\dot{\\xi_R}}}$ 根据此以及Brockett定理可判定对于这个模型，没有光滑的反馈控制 根据Chow定理是可控的   非线性控制器  记机体坐标系下误差信号为 $e=[e_1,e_2,e_3]^T$ 可令 $v(t)=-k_1 e_1$ ，单纯的比例控制 可令 $\\omega(t)=-k_2 e_3 + {e_2}^2\\sin(t)$ ，比例控制加前馈 如此带入误差的动态模型 $\\dot{e}$ 可以进行稳定性分析   极坐标线性化  $\\tilde{q}=[\\rho, \\alpha, \\beta]$ 误差模型则是 $\\dot{\\tilde{q}}=\\bold{A} [v,\\omega]^T$ 控制器则可以令 $v=k_{\\rho}\\rho, \\omega=k_1 \\alpha + k_2 \\beta$ 带入到误差模型里后还是存在三角非线性，因为 $\\alpha$ 始终比较小，可以做三角函数的线性化得 $\\dot{\\tilde{q}} = \\bold{A_{linear}} \\tilde{q}$ 由Hurwitz判据知系统指数收敛，又近似了LTI，所以渐进收敛     误差模型的推导 \n 控制器和线性化 \n 稳定性分析 \n 并不是说极坐标一定要线性化，也可以指定 $v,\\omega$ 为其他的函数，非线性的也可以，只不过就得用Lyapnuov理论了\n一般方法都是得到误差状态变量的导数与 $[v,w]^T$ 的关系（误差模型），然后设计控制率，也就是 $v, w$ 的关于状态变量的函数，然后带入到误差模型中，得到误差的动态，对其做稳定性分析\n 轨迹跟踪控制  $q_r$ 这时候是规定的一条轨迹了，类似上面的定点控制 更高级的在这里有「横向自动控制方法：Purepursuit, Stanley, MPC对比」   规划 几个基本概念  The workspace is often the representation of the world, possibly independent of the robot itself. Often describes some notion of reachability, what space is free or occupied? 不一定是笛卡尔空间，关节空间或者参数空间都可以 Configuration space describes the full state of the robot in the world (actuator positions, orientation, etc.) Let’s consider that our robot is no longer a point, but occupies an area\u0026hellip; structured: occupancy grid map, distance field; Unstructured: graph, mesh, exact  基于搜索树的路径查找  一个很好的视觉实现 广度优先搜索BFS  从起点开始，首先遍历起点周围邻近的点，然后再遍历已经遍历过的点邻近的点，逐步的向外扩散 一旦到达终点，便可以从终点开始，反过来顺着父节点的顺序找到起点，由此就构成了一条路径 完备   深度优先搜索DFS  从起点开始，不断沿着路径进行扩展，直到找到终点或者无路可走，再重新选取父节点进行深度搜索 不完备，可能无限走错路   Edsger W. Dijkstra  寻找图形中节点之间的最短路径，需要计算每一个节点距离起点的总移动代价 节点放入优先队列中会按照代价进行排序，运行时优选选出代价最小的作为下一个遍历的节点 Asymptotically the fastest known single-source shortest path algorithm for arbitrary directed graphs Doesn’t really know the goal exists until it reaches it   从Dijkstra到A*  综合代价=代价+启发函数 优先选取综合代价小的节点作为下一个路径点 启发函数是节点n距离终点的预计代价  估计值 $\u0026lt;=$ 实际代价：一定能找到最短路径，估计值越小则遍历的节点越多 估计值 $=$ 实际代价：一定能找到最短路径，最理想的情况 估计值 $\u0026gt;$ 实际代价：不能保证找到最短路径，不过此时会很快，若远大于则变为最佳优先搜索   在低维度空间里很常用，限制是需要构造一个图，启发函数比较难找，比较难栅格化     Dijkstra和A*区别 \n D*: Dynamic A*  动态环境下可能各种条件代价会变化所以进行了改进    基于采样的路径查找  主要是为了防止维数爆炸，防止连通性降级，以及直接在config空间里（不好grid化）直接plan 主要思路  在config空间中采样（uniform，gaussian，obstacle involved） 将新采样点和附近的已有点进行连接，判据一般是范数 检查碰撞（计算量大户），如果没碰撞则添加一条边到路径中 检查是否到达目标（附近） loop     范数 \n Probabilistic Roadmaps (PRM, 1996)  特性  为multiple-queries设计，允许大量预先计算 对于single-query问题则可以省略一些预先计算来加速 先全图采样完再寻找一条路径   主要步骤  在空间中sample一堆没有碰撞的点 用这些点构造一个图，包括碰撞检测 使用A*做搜索   限制  限制为完整约束运动 窄通道无视问题 动态环境不适用     Rapidly-exploring random trees (RRT, 1998)  不断生长的树，而不是把全部空间都采样完 designed for single-query search 适用于非完整性约束运动和动态环境，比PRM更容易整合控制和运动学约束 可用于高维空间问题，无需几何划分，可以尽可能的探索未知区域 改进型  Goal-Bias：将目标节点作为采样点出现，可以控制目标点出现的概率 Extend RRT：引入路径点集合，加快了收敛速度，提高了路径的稳定性 RRT-Connect：初始点和目标点生成两棵树，直到两棵树连在一起算法收敛 Local-tree-RRT：对随机采样算法狭窄通道难以迅速通过的问题，提出局部树方法加以解决 Dynamic RRT：提出了修剪和合并操作，去除掉无效的节点后再继续进行搜索      局部规划（避障）  BUG算法 动态窗口：认为一小段时间内twist恒定  势场法  主要思想：避免层级结构，同时考虑全局和局部路径，建立一个全局势能场，机器人自动沿着最大梯度方向下降到目标点 一种常见的实现：总场=目标场+障碍场   目标场 \n 障碍场 \n 总势场 \n 传感器大类和指标 分类  \n 常见传感器 \n常见传感器的原理  rangefinder  TOF  sonar lidar   RSS   infra-red：发光二极管发出包括红外的光，由物体反射，传感器接收检测强度  主要性能指标  动态范围 测量范围 分辨率 线性度 频率/带宽 误差  系统误差由理论上可建模的因素或过程造成，是确定性的（deterministic 知道解析形式的），可测的    标定和不确定性  标定：确定一个从传感器读数到有意义数据的映射  获得ground truth和测试数据 拟合模型   不确定性一般处理办法  储存测试值和准确值的pair 获得确定性变换模型 获得概率模型（比如假设高斯分布）  可以用平均值（第一moment）和方差（第二moment） 贝叶斯公式       基于视觉的感知 CV的常见应用  语义分割 图像分类 目标检测 实例分割 目标追踪 三维重建  相机图像获取  小孔成像-\u0026gt;光圈虚化原理-\u0026gt;使用透镜 小孔成像与透视原理  radial distortion intrinsic calibration: Use camera model to interpret the projection from world to image plane  To estimate 11 unknowns, we need at least 6 points to calibrate the camera (linear least squares)      数字图像处理  相关和卷积，都是对应位置相乘之后相加，但是卷积的核要倒过来，但是因为图像处理中基本是对称的，所以区别不大 空间滤波基础（模糊和锐化） 边缘检测，一阶和二阶导数的区别，如果加入了高斯模糊，则一阶对应用gussian一阶导DOG卷原图，二阶对应LOG卷原图 图像匹配  normalized cross correlation zero-mean correlation dot product    立体视觉  Triangulation：给出一组对应的图像坐标和相机位置，确定像素对应点的3D位置  geometric approach linear approach non-linear approach   Stereo camera  标定：外参数（relative pose between the cameras (rotation, translation)）；内参数（focal length, optical center, radial distortion） 像素匹配  Epipolar Constraint  Epipolar rectification: warps image pairs into new “rectified” images, whose epipolar lines are parallel \u0026amp; collinear (aligned to the baseline) 计算相似度来匹配，Typical similarity measures: Normalized Cross-Correlation (NCC) , Sum of Squared Differences (SSD), Sum of Absolute Differences (SAD)   得到像素的匹配之后可以获得视差图：同一个场景在两个相机下成像的像素的位置偏差，因为通常下两个双目相机是水平放置的，所以该位置偏差一般体现在水平方向   对双目成像来说，视差图和深度图在某种程度上是等价的，知道了两个相机的相关参数，是可以将视差图转换为深度图的（最近有工作直接用AI输出深度图） 双目间距的影响：太小则深度误差大看不远，太大则看不近   Structure from motion (SFM)  Simultaneously estimate both 3D geometry (structure) and camera pose (motion): solve via non-linear minimization of the reprojection errors    光流（Lucas–Kanade）  根据相邻两帧图像估计运动信息 三个假设  光强（像素值）不变： $I(x,y,t)=I(x+dx,y+dy,t+dt)$ 时间差较小： $dt=0$ 空间相关性，空间不变形   步骤图如下   \n 光流法 \n点检测   Harris Corner \u0026amp; Shi-Tomasi（可判断是edge类型还是corner）\n 同平面旋转不变性，线性光照强度变化不变性；但对于尺度和仿射变换没有不变性 corner的一个特性：Shifting a window in any direction should give a large change of intensity in at least 2 directions   \n 角落检测一般分析思路 \n 特征值的解法 $det(A-\\lambda I)=0$   Eigen Visualization \n Shi-Tomasi \n Harris实际上也可以采用单阈值筛选 \n  解决特征检测的尺度变换问题\n Scale detector  思想是根据不同的图片尺度选择不同大小的检测区域大小/shifting region大小 Sharp, local intensity changes in an image, are good regions to monitor for identifying relative scale in usual images  Use DOG and LOG convolve image with kernel to identify sharp intensity discontinuities     SIFT = Scale Invariant Feature Transform: an approach for detecting and describing regions of interest in an image  invariant to changes in: rotation, scaling, illumination Very powerful in capturing + describing distinctive structure, but also computationally demanding      一些快速算法\n FAST corner detector BRIEF descriptor，Not scale/rotation invariant (extensions exist\u0026hellip;) BRISK （快，仅次于BRIEF，但旋转和尺度不变）    线检测  算法比较  Split-and-merge and Line-Regression: fastest  best applied on laser scans Deterministic \u0026amp; make use of the sequential ordering of raw scan points   If applied on randomly captured points only last 3 algorithms would segment all lines     一图对比 \n  Hough没什么好说的，参考DIP\n  Split-and-merge\n   \n full process \n  Linear regression\n line regression \n  RANSAC: RANdom SAmple Consensus.\n A generic \u0026amp; robust fitting algorithm of models in the presence of outliers (i.e. points which do not satisfy a model) Typical applications in robotics are: line extraction from 2D range data, plane extraction from 3D data, feature matching, structure from motion, camera calibration, homography estimation, etc. iterative and non-deterministic, the probability to find a set free of outliers increases as more iterations are used a non-deterministic method, results are different between runs    地方检测  地方的图像抽象为bag of words：We can describe a scene as a collection of words and look up in the database for images with a similar collection of words 图像各种feature通过某种方法得到descriptor space里面的一个个点，用k聚类算法归类  k-means  先定义总共有多少个类/蔟 (cluster) 将每个蔟心 (cluster centers）随机定在一个点上 将每个数据点关联到最近蔟中心所属的蔟上 对于每一个蔟找到其所有关联点的中心点（取每一个点坐标的平均值) 将上述点变为新的蔟心 不停重复，直到每个蔟所拥有的点不变     根据聚类生成一个单词树，树的最末端代表word，上一级代表一个聚类，拿去跟训练好的模型进行比较即可知道是什么单词   移动机器人的定位 相关概念  Perception : the robot must interpret its sensors to extract meaningful data; Localization : the robot must determine its position in the environment; Cognition : the robot must decide how to act to achieve its goals; Motion control : the robot must modulate its motor outputs to achieve the desired trajectory.  挑战  noise: illumination, jitter, gain, bloom, blur sensor aliasing (混叠) odometry  Limited resolution during integration (time increments, measurement resolution, etc.); Misalignment of the wheels (deterministic); Uncertainty in the wheel diameter and in particular unequal wheel diameter (deterministic); Variation in the contact point of the wheel; Unequal floor contact (slipping, nonplanar surface, etc.) error types  Range error: 积分 integrated path length (distance) of the robot’s movement, sum of the wheel movements Turn error: 运动学参数 similar to range error, but for turns, difference of the wheel motions Drift error: 打滑 difference in the error of the wheels leads to an error in the robot’s angular orientation      差速模型里程计误差  基于RK2的运动学模型   运动学模型 \n 误差传导模型结论   新的协方差矩阵 \n 可视化 \n马尔可夫定位  Markov localization tracks the robot’s belief state using an arbitrary probability density function to represent the robot’s position   markov流程 \n 对于2D定位，需要实时更新一个立方体的数据，很慢  One possible solution would be to increase the cell size at the expense of localization accuracy. Another solution is to use an adaptive cell decomposition instead of a fixed cell decomposition. reduce the number of states that are updated in each step    卡尔曼滤波定位  卡尔曼滤波是迭代的，线性系统高斯噪声下最优的，实时性好   kalman流程 \n kalman update \n  卡尔曼滤波器和信息融合\n kalman fusion \n  ","date":"2021-12-29T15:24:52+08:00","image":"https://ercbunny.github.io/p/notes-for-introduction-to-autonomous-mobile-robots/cover_hu51328586977ed3b7b80ac2bd02aacb27_216134_120x120_fill_q75_box_smart1.jpg","permalink":"https://ercbunny.github.io/p/notes-for-introduction-to-autonomous-mobile-robots/","title":"Notes for Introduction to Autonomous Mobile Robots"},{"content":" 先来说说结果  Oct10在广外大学城考的是V150，Q166，AW4 Dec12在赛格人才培训中心考的V160，Q168，AW应该不出意外4还是可以的 好像两次Q都有问题啊，听说不满分不是冲国人是吗呜呜呜，反正再您*的见哇哈哈哈哈哈（请脑补荒泷派笑声   旅途一波三折   最开始决定要考GRE是在暑假时套瓷的时候破了个防，HK那边没有老师明确说愿意收我，如果不考GRE那很多地方都去不了，就……应该八月底左右开始准备来着。怎么说，当时应该是高估了自己的能力，背3000也是一直在abandon（笑），觉得在雷哥网上练了几套自适应模拟题熟悉了一下题型就可以了。就这？对，就这……\n  然后当然3000都没背下来，考前是国庆还一口气把「进击的巨人」给补完了……（悲，离谱）。考试当天，起了一个大早坐地铁，到地铁站突发恶疾然后还滚去某个昏暗的WC里解决了一下……到了大学城北还得坐公交过去，下车了还得走一大段路。然后考试中基本上大脑一片空白，1080P屏幕实在是辣眼睛，鼠标和键盘声属实难顶唔。不过偶遇好多老同学哈哈哈。嘛，这次就战略性放弃了（逃\n  回到家之后还是决定二战Nov7，毕竟这时候停止自己也咽不下这口气。但具体怎么做还是很迷茫的，就先认定是词汇量不行，打算先把机经1300生词给过了一遍，之后继续认真刷3000了。后来雷宝（yyds）出分了，告诉我主要是做题，我觉得有道理，3000也就大概过了2000词然后滚去做机经了～到Nov7的时候大概刷了200左右选择填空题（Q和AW基本有手就行，就完全没管过），打算就这么迎接二战\n  离谱的事情是深大医院当时没能在合适的时间给出核算检测结果导致当天没办法考试……还好能退钱，然后赶紧预约后面的Dec12，还是广外。当时还发了个说说狠狠批判了自己\n     在要求成功率1的情况下选择已验证可行的方法会比较好\n  回执凭证这些拿到手上一定一定一定要检查信息\n  还是要提前做准备，最好关键时刻前一天要double check\n  规则就是规则，不要想着侥幸；提前补救比赌规则要有用的多\n   然后就是继续刷机经咯，最后是刷了800多个选择填空题，KPP5套左右的完整Verbal……其实在Dec8左右收到广州考试被取消的短信，当初差点就想放弃了的说。最后还好深圳还有座位而且没有放弃，要不然真的就是寄了（最后发现赛格那边真的很不戳，方便，环境好，工作人员也更nice一点儿）。说实话，如果要我那个时候去考可能还真不一定就能过，所以很难不想起下面这一段话    那么人呐就都不知道，自己就不可以预料。你一个人的命运啊，当然要靠自我奋斗，但是也要考虑到历史的行程。我绝对不知道，我作为一个……怎么把我选到北京去了，所以…跟我讲话，说“中央都决定啦……”，我说另请高明吧。我实在我也不是谦虚，我一个……怎么跑到……去了呢？但是呢，……“大家已经研究决定了”，所以后来我就念了两首诗，叫“苟利……”，那么所以我就……。   Dec12考试当天：7点半起床，洗漱吃早餐，放空自己（物理意义上）。8点10分左右网约车出发往市中心去，9点不到就到了考试中心，（有电梯，各种设施齐全干净，指引齐全，好评）。考完试大概一点四十左右，在华强北DJI，Apple店里溜达一下，玩一玩公共钢琴，跑去地下茶餐厅吃个午饭，天气很好，心情当然也不错～   一些备考建议 Verbal  词汇量部分可以先认真学一遍张巍老师的机经生词伴侣以及等价词，然后用Excel过一遍3000词（这个表格是B站上某个视频下分享的，忘记来源了，侵删）；背3000的时候不要太死心眼了，实在记不住就算了，只求有个大致印象就可以，免得影响心情。   填空机经1300题生词伴侣.pdf\n真经GRE等价词汇总.pdf\n要你命3000词表.xlsx\n  对我帮助比较大的是刷题。把考满分（还挺好用，比雷哥网的网页写得好，评论区也好玩）的经典填空题至少刷完90个小节，当然越多越好，但是刷完90也基本差不多了。10min一个小节，不能再多了，顺便要注意练习节奏。阅读也可以做，但我自己的阅读还可以就放养了……模考可以用来练习整体节奏，我是把base+medium和hard以及KAPLAN下面popular的给做了  Quantitative  没有多余精力，没有满分需求的同学建议裸考 要满分的话还是刷点题吧，有些条件概率在英语语境下我经常会寄，其他基本是有手就行  AW  基本观点是，逻辑清晰为上，结构直白就行，不求perfect，但求good和properly written，关键是自圆其说 30min能写得越多越好，但在此之前结构完整更重要（不要虎头蛇尾） 可以参考这个油主的一些视频，可以获得最基本的一些概念 Issue（论点+论据）：  第一段=背景（题干信息）+我的论点+描述文章结构 body几段的每一段（也就是为什么）=中心论点+阐述逻辑+例子+回扣论点 避免绝对说法/让步段 总结=rephrase in a more sententious way   Argument（挑逻辑漏洞）：  原文论点+声明题干要求 分段阐述逻辑，可以quote原文 回扣题干要求    ","date":"2021-12-12T21:40:00+08:00","image":"https://ercbunny.github.io/p/%E3%81%95%E3%82%88%E3%81%AA%E3%82%89gre/cover_hu77614c637fc6c9a84dc47c4d43e7b525_303754_120x120_fill_box_smart1_3.png","permalink":"https://ercbunny.github.io/p/%E3%81%95%E3%82%88%E3%81%AA%E3%82%89gre/","title":"さよなら〜GRE"},{"content":" VIDEO DEMO \r\r RELATED LINKS   Source Code\n  View Project Report PDF (Chinese)\n   Contents of the detailed report are in Chinese as they were made originally to support the Chinese presentation. A rework and translation of illustrations, diagrams and the report is in progress, but don\u0026rsquo;t expect it to be finished soon. Best regards~\n ","date":"2021-11-13T16:37:33+08:00","image":"https://ercbunny.github.io/p/dash-to-cones/cover_hu1596c4524e5e256ae3691ce675d04ab7_1474265_120x120_fill_box_smart1_3.png","permalink":"https://ercbunny.github.io/p/dash-to-cones/","title":"Dash To Cones"},{"content":" 这篇Post是啥 \r\r  在这个视频的结尾部分有一堆问题，之前截了图下来，在这里我写一下现在的回答，大概可以反映现在这个时刻我的世界观和人生观，之后回过头来看也许是很有趣的事情。最后编辑于2021年12月27日。\n  看到知乎上一篇有意思的回答，引路\n   第一面  第一面问题 \n同学们都各有去处，我又要在何处落脚呢？ 去处的话投了下面这几个地方的学校：香港，瑞士，荷兰，加拿大，新加坡，哪里要我就去那里吧\n为什么简历投出去总是没有反应呢？ 不够优秀或者是那边人招满了或者投递的时间不对\n我的专业真的有前途吗？ 只能说是事在人为，除非有很强烈的证据推断，一切空头预测都没意义。至于自动化/控制/机器人这个专业，有很多东西可学，学成了也有很多东西可做，学到的思路更是可以应用在其他领域\n我可以找到称心如意的工作吗？ 应该可以吧，这个不喜欢就想办法换吧\n我什么时候才能过想要的生活？ 笑死，根本不知道想要什么生活，而且愿望是会变的，只能动态行动并决策\n努力真的能有收获吗？ 我认为有，但可能收获不一定和“期望的那样”关系非常大\n真的要一份工作伴随终老吗？ 不需要，不喜欢被工作束缚，但是如果有一个值得我倾注所有精力的事业，我也非常愿意和它终老\n学历是否真的是成功的关键？ 不是，因为可以举出反例。但是对于大部分理性的决策者来说，要在获取学历和不获取学历之间选择，那肯定会选获取学历\n只想回老家朝九晚五，是不是没志气？ 不是，生活的目的（如果真的有目的的话）的最高抽象我觉得是获得快乐（可以分为低等级/直接/高等级/间接），而实现自己愿望/做自己想做的事情就是一种途径，如果说朝九晚五就是想过的生活，为什么还要考虑别人对志气的评价\n现在选的这条路，走错了怎么办？ 如果是尊崇自己内心的觉悟选择的路，走错了也没关系，改就好了。知道什么不适合自己也是收获\n第一份工作，到底对我的末来有多少影响？ 这个真的一点看法都没有，未来求解答\n怎么快速融入公司和同事？ 知识盲区\n没有老师再教我了，该怎样自学自立？ 我上大学就基本没听过课诶\n专业不对口的公司会要我吗？ 大概率不会，但如果技术过人满足要求的话为什么不要\n创业公司还是大公司，选哪条路才是对的呢？ 我觉得看待遇吧\n我们的爱情能经受住距离的考验吗？ 爱情，呜呜呜，爱情是什么，能吃嘛\n如果我们毕业后在同一个城市，是否能有更好的结局？ 无可奉告\n还有人能陪我去做那些很冒险疯狂的梦吗？ 总会找到志同道合的小伙伴的，就算没有，独自前行未尝不可\n离别时真心地想要常联系，但最后都会逐渐淡忘彼此？ 那只能说心愿没有强烈到一定程度\n我们还能在深夜的烧烤摊诉说到天亮吗？ 在深夜的烧烤摊诉说到天亮也太难受了，我比较喜欢睡觉，睡不着的话学语言吧，一下就困了\n以后我也能找到一起并肩奋斗的朋友吗？ 能\n毕业以后,还有机会再见到你们吗？ 不是有没有机会吧，是心愿是否足够强烈决定能不能再见面滴\n喝醉之后打通的电话，还会是我吗？ 不喝酒，谢谢，而且根本没人打电话给我哈哈哈\n以后谁帮我带饭，谁陪我逃课，谁又能带我喝遍后街的奶茶呢？ 外卖yyds，逃课还要人陪嘛笑死，探店这种事情嘛，每个阶段都会有不同的朋友一起的吧\n我还能遇见更好的人吗？ 股票还会继续涨吗（笑\n我们会永远在一起吗？ 你曾说过不分离，要一直一直在一起，现在我想问问你是否只是童言无忌\n他们说毕业就必定分手，我们也逃不过这个定律吗？ 没有这种事吧，谁说必定了？这不轻易举出反例吗，想分就分不想分就别分啊，多愁善感算什么啊\n是不是所有的轰轰烈烈，到最后都会变得「平淡如水」？ 大部分好像是这么回事，但是可能也有例外\n遇见真爱的几率，和彩票中奖的几率，究竟谁大 知识盲区x2\n爱而不得，是人生常态吗？ 是，大部分时间都是花在追求这个过程中，不就是一种爱而不得嘛\n 第二面  第二面问题 \n大城市里还留得住我的梦想么？ 可以哦，特别是与当地人好上之后\n还没来得及拥抱的你，是不是再也无法无法相遇了？ 不是\n我还能有机会偷偷描摹你的侧脸吗？ 我感觉这不是个问题，是一个感叹，哭了\n如果现在不告白，我是不是就再也见不到他她了？ 不是\n我能养活自己吗？ 能\n没有考上理想的大学和专业，大学四年是不是浪费？ 不是，因为可以主动去找喜欢的事情做\n就算表现总是优异，还是会自卑怎么办？ 人比人，总会有自卑的时候，但是最好是能把他转换为动力\n对于世界来说，善良和能力哪个更重要？ 都不重要，世界意识真的会管人类吗\n我会过上复制粘贴的生活吗？ 不会，我会尽量避免\n我可以适应毕业以后的孤独吗？ 可以\n我会变成曾经最讨厌的模样吗？ 我会试图避免\n我还能保留住自己的初心吗？ 会试试\n我只想做个普通的平凡人就是浪费生命吗？ 不是，他人没资格评论一个人的生命是否被浪费了，我还是觉得人应该优先遵循自己的愿望和想法\n什么样的人生才是有意义的呢？ 见2.9\n工作以后就无法拥有自己的生活了吗？ 社畜哭泣，但是如果让他们躺平肯定也不愿意，因为他们知道当社畜是在追寻某种东西，金钱地位也好，城市的生活也好，在这个意义下也算是自己的生活\n工作没有对方好，就配不上对方吗？ 学习成绩没有对方好，就不能和对方谈恋爱吗\n学历低就无法看到更广阔的世界了吗？ 不是\n怎样才算不虚度时光？ 追寻内心，为其所欲，行其所想，唱自由向往\n长得好看就能过得更好吗？ 不是，但是长得好看大概率能过的更好\n我能适应陌生的城市吗？ 能\n我会变得更优秀吗？ 会\n我现在该做什么，将来才不会后悔？ 迷茫中，没办法预测太久之后的局势，但是我会追寻内心，为我所欲，行我所想，怎么都不会后悔\n毕业后我也可以像在学校这么快乐吗？ 也许吧\n喜欢打游戏，就是玩物丧志吗？ 不是\n喜欢化妆，就是肤浅吗？喜欢画画，就赚不到钱吗？ 不是\n将动漫作为人生目标，是浪漫，还是太过天真？ 那肯定是浪漫啊，人不中二枉少年啊，你说天真当然可以啊，毕竟“天真浪漫”嘛，但是没做伤天害理的事情凭什么被说过分啊\n看不到希望的梦想，没有人支持的梦想，我该放弃吗？ 不该，既然是梦想，说明是想做的事情，如果是我就不会放弃，就算真的有很大的弊端，我也会走曲线救国的方法\n我可以成为我想成为的人吗？ 不知道诶，頑張ります\n我可以一辈子只做自己喜欢的事情吗？ 大概率做不到，有时候为了达到特定的心愿的时候需要强迫自己做一些不喜欢做的东西，这也是为什么说必先苦其心志饿其体肤……还有鲁鲁修那个作品……\n毕业之后，我是不是终于可以掌控自己的人生了？ 一定程度上是的吧，自己的决定更加重要了，虽然有时候会遭到不可抗力的阻挠（所以说不上掌握），但是也算是能够自己决定大概走向了\n","date":"2021-08-01T11:07:12+08:00","image":"https://ercbunny.github.io/post/outlook/%E5%85%A5%E6%B5%B7cover.jpg","permalink":"https://ercbunny.github.io/p/%E5%85%A5%E6%B5%B7mv%E7%BB%93%E5%B0%BE%E9%97%AE%E9%A2%98%E6%88%91%E7%9A%84%E7%AD%94%E6%A1%88/","title":"入海MV结尾问题我的答案"},{"content":" VIDEO DEMO \r\r OVERVIEW  We were required to program QKM manipulators to play Jenga automatically My part was doing hand-eye calibration, blob analysis, path/trajectory planning and simple UI The robot operates like this:  Take a picture with camera and calculate target positions Do path and trajectory planning Upload planned trajectory to bot Run     HAND-EYE CALIBRATION HEC Explained in A Nutshell  Aims to find the transform matrix from camera frame to tool frame. Intrinsic params: cv::calibrateCamera() Solve for pose of the calibration board in camera frame: cv::solvePnP() Solve for end effector transformation matrix and use cv::calibrateHandEye() to finish the process  Solving the AX=XB Problem  HE Calibration Illustrated \n Consider the transformation $T_{E_1 \\rightarrow C_0}=g_{1_1}^{-1}g_{1_0}g_2=g_2g_{3_1}g_{3_0}^{-1}$, where $g$ stands for the configuration of a frame By taking N pictures, we can make use of N equations to solve $AX=XB$ Actual solver is implemented by OpenCV: cv::calibrateHandEye() Subproblem 1: How to find $g_{3_i }$?  cv::calibrateCamera() cv::solvePnP()   Subproblem 2: How to find $g_{1_i }$?  Forward kinematics     Solving Subproblem 1 \n JENGA DETECTION   Blob Analysis:\n RGB to HSV Get blob areas based on color filtering Apply morphology process to eliminate cracks and dots Find blob contours and corresponding minAreaRect    Coordinates transformation:\n Pixel frame to camera frame: $q_{pixel}Z_c=KDq_{camera}$ Camera frame to world frame: $q_{world}=g_1g_2q_{camera}$    Sort targets by the distance to base in ascending order, because we need to take into consideration of the height of already built structure and make sure that the planned path does not crush it\n   TRAJECTORY PLANNING   Linear function with parabolic bends and via points Apply inverse kinematics with given starting, ending and via points to find corresponding points in joint space\n  Doing trajectory planning in joint space directly is much faster because of absence of calculating inverse\n  To avoid collision and damage, trajectories are first visualized in MATLAB\n   Trajectory Visualized \n RELATED LINKS  Source Code  ","date":"2021-07-01T15:24:52+08:00","image":"https://ercbunny.github.io/p/hljenga-hexalink-jenga-manipulator/cover_hu0850b6c007daea2e7b374a0a29db32b6_4012887_120x120_fill_box_smart1_3.png","permalink":"https://ercbunny.github.io/p/hljenga-hexalink-jenga-manipulator/","title":"HLJenga: Hexalink Jenga Manipulator"},{"content":" VIDEO DEMO \r\r PROJECT OVERVIEW   Nothing interesting or related to cutting-edge research. Just an engineering level practice\n  Some technical approaches:\n Localization: optical flow, TOF sensor Detection and navigation: YOLO + KCF + Hough Circle Transform on TX2 Flight controller: ACFLY ADRC Communication between FC and TX2: velocity command through serial UART     DETAILED REPORT   View Control and Electronic Circuit Design Scheme PDF (Chinese)\n  View Structure Design Scheme PDF (Chinese)\n   Contents of the detailed report are in Chinese as they were made originally to support the Chinese presentation. A rework and translation of illustrations, diagrams and the report is in progress, but don\u0026rsquo;t expect it to be finished soon. Best regards~\n ","date":"2021-04-23T14:55:42+08:00","image":"https://ercbunny.github.io/p/autonomous-delivery-drone/cover_hu3a5654af451f72d615660f99e36c46aa_3411183_120x120_fill_box_smart1_3.png","permalink":"https://ercbunny.github.io/p/autonomous-delivery-drone/","title":"Autonomous Delivery Drone"},{"content":" VIDEO DEMO \r\r\r\r LINKS   Open Source Repository\n  Daily Update of Captured Images (Onedrive)\n  ","date":"2021-01-22T16:37:33+08:00","image":"https://ercbunny.github.io/p/pytimelapse/cover_huc1a5e2943fc7a390a74a968662e68c26_382039_120x120_fill_q75_box_smart1.jpg","permalink":"https://ercbunny.github.io/p/pytimelapse/","title":"pyTimelapse"},{"content":"元旦左右的时候按照习惯是会写一个年度小结之类的东西。但当时有一堆事情要做，复习机械之类的，然后心态也稍微有点爆炸所以就拖到现在10号了，老实说如果当时不是在onenote里给自己定下了“要写个总结”的计划，我估计就懒得写了。\n这里主要就是想对着onenote回顾一下这一年做了些啥，体会一下心态的变化，为啥是onenote呢，我习惯在onenote里面规划自己的日程。曾经想过要不要把onenote迁移到notability上，想了想又还是觉得算了，毕竟我还是挺喜欢onenote那种无限大的页面，不会被纸张大小局限的感觉。\n新的一年给我的感觉好像总是从冬天、寒假开始，而不是人们常说的春夏秋冬这个顺序。2020年的寒假开始于13号，当时花了四天时间把电路书讲cadence的章节给看了，上手了这个软件。啊，竟然还是不到一年前吗？真的很难想象这一年我都经历了什么以至于到最后做电机仿真的时候都有一种已经认识这个软件两三年的感觉……大概是一堆远程仿真实验吧……寒假期间终于在许多次找场地、试飞和修理后体会到了固定翼FPV飞行的乐趣（DJI还是牛的），确实很爽，但一个人玩终究还是孤单了一点哈，而且尾推式的飞翼起飞的时候有点麻烦。下次可能就弄一个尾座式VTOL，加上头部追踪云台，和小伙伴们一起飞吧。看书的话主要就是把电路剩下的那几章给学完了，作业也做了，总结也做了。虽说最后复习的时候还是得重新做一遍的，但还是给我省下了一点在电路课上啃模数电（以及摸鱼）的时间。\n这个寒假绝对是最最最特殊的一个寒假，一开始从15截止延期到29号，最后直接无缝过渡到春季学期，现在回忆起来也没有觉得春季学期有什么实感，好像还是放假的感觉。造成这种情况的源头是很大概率会被载入史册的COVID19。当时天气尚冷、新闻里不断播报着疫情的蔓延和城市的封锁，真的给人一种非常压抑喘不过气来的感觉。要命的是我还突然开始咳嗽了，当然不是新冠而是普通的着凉那种。虽然当时也心里很明白大概率只是着凉了，但是当时真的很恐慌啊也不知道该不该去医院，处于一种进退两难的地步，我还去问了我一个学医的学长，现在想起来简直是xswl。咳嗽这种东西啊，你越去想就越想咳——后来沉迷于罗小黑和三蹦子，就没怎么去管咳嗽是不是新冠这档子事情了。我好像是把这有关这两个IP的几乎所有作品都给补了一遍……对了对了，受008的启发我也做了一个类似的视频，虽然莫有什么人看，但是做视频的那几天还是挺快乐的（沙雕并快乐着），是疫情期间少有的闪光的日子。\nSpring2020给我的总体感觉是在应付一堆没有什么意义、甚至有些愚蠢的远程仿真实验的同时啃一堆我自己并不感兴趣的课程的书。这里特别要diss一下什么elf-box平台，真的是过于愚蠢，以至于现在我回想起那丑陋的UI和操作逻辑和莫须有的存在意义就觉得恶心QAQ。至于数电模电学的怎么样呢，嘛，最后数电考前没有做模拟题，手生得一批，模电做了些题，但考得有点偏，做过的一些题好像也做错了，就真的难顶。而且，真要我去看实际的工程原理图我还是看不懂……结果我这一学期做的事纯粹是为了以后能获得更多的资源在卷，完全没有任何学得开心的感觉。春季学期还做了一件事情，就是申请本科期间的UCB交换项目，有个同伴一起准备还是真的挺不错的。我们可以同步信息，一起练习口语（尬聊摸鱼），所以准备过程还是非常轻松的。之前我20年元旦写道：如果不出意外的话再过一个学期就可以去交换了……然后果真出意外了，所以申请到之后与那边不断联系的过程是令人焦虑的，最后是再三推迟，一直推迟到了大四学年，到时候看自己更加清楚自己发展方向之后再决定去不去吧。umm，大概率是会去的，毕竟想申HKUST，这种经历应该也是比较重要的叭。\nSummer2020以及暑假主要就是做金工实习、复习备考和准备MCM。当时是回学校弄金工实习，一开始同学们见面都超级开心，热烈地讨论着这次的疫情和寒假。过了一两个星期，这份热情满满消退，熟悉的日常渐渐回归，宿舍里生活习惯的矛盾也变成了令人烦恼的东西。我比较习惯12点睡觉，但是通常这个时候有些人就习惯嗨，鼠标按的那是一个响啊，嘀嘀嗒嗒哈哈哈哈……于是做完金工实习我就滚回家去了。但是回家了就万事大吉了？我也是图样图森破了，楼下竟然有两家在同时装修，早上八点冲击钻会准时沿着钢筋和横梁从下面几层钻上来，钻进被窝把我震醒，然后一直持续到晚上六点，整个人都要炸毛了，更别说学习数模了。我也不知道我怎么习惯的，当然了你不习惯也得去习惯不是吗……后来终于可以回学校了，这个噩梦也算是结束了。关于MCM，确实是一次特别的体验，我们队伍换了两次题目，最后水了个省三，也算是……不错……吗？我们确实没有怎么很上心去准备最后还能勉强写出一篇过得去（？值得商榷）的文章。当然了，也有隔壁第一次打美赛就进了Finalist的，嗯，菜是原罪。MCM的结束也正式为整个大二画上了一个句号。\nFall2020开始，我喜欢在日程表旁边记一下有趣的论调或者吐槽一下身边的事（吐槽居多）。9月20号左右的时候去羽协的进阶小队玩了一下，被乱杀，实在是太久没打了然而还自我感觉良好，这不吃瘪谁吃瘪……10月30号记下了一份在自控课上听到的有意思的观点：作报告和学术交流要以强调能解决什么问题和解决的思路为主，背后的推导往往是在会议/演讲中不重要的，因为那些都是值得拿纸和笔细细推敲的东西，自然没人愿意在嘈杂的环境中仔细听的……11月15号被安利了一部《总之就是非常可爱》的漫画，然后发现作者也是非常可爱啊，有些观点竟然与我不谋而合，比如在学一些精巧的设计的时候我总会觉得很痛苦，感觉被降维打击了，这时候我会这么安慰自己：这些精巧的设计和知识都是前人智慧的结晶，应该抱着敬畏心去学习，退一万步讲，现在我只需要去看懂和学会怎么用就行了，和前人们的工作比起来已经是相当容易的了。再比如之前我认为为了达成某个大的目标就应该把时间全花在那个事情上面而对自己加一些约束不应该把任何时间花在其他事情上面，当时觉得这么想没什么，但是回过头来发现这种思维已经是非常病态的了。主旋律固然重要，但是遇到想要做的事情，只要不是特别不合理，就勇敢的去做吧，很多事情就是一念之间，也许现在不做以后再也没有机会了……再后来，复习机械的时候，连续几天都在吐槽机械的讲义，和自控比起来简直是太逊了，知识点零散没有逻辑，没有提出具体要解决什么问题，显式地提出有意思的问题和后面的解答是同样重要的，以后自己也要注意这一点，望引以为戒……还有好多条我这里没有摘下来，再摘就要变成流水日常了。还有一个有意思的项目是工地延时摄影计划，打算做个跨越一年多时间的延时摄影。毕竟深圳·哈尔滨工地大学让我好多次带着痛苦面具起床，我至少得记下来到底是啥让我那么痛苦，话说为啥哪里都是工地啊喂！有人说这很疯狂，又不能算作项目报销得自己掏钱，又花时间……我是筹划这个东西有一个学期了，还是那句话有些事情现在不做以后就没机会了。\n2021的愿望是世界和平，我认识的人都能身体健康，然后是也希望自己能找到更多让自己觉得快乐且有意义的事情，能漂亮地完成自己下定决心要做好的事情。\njan19 2021补充：下定决心要做好的事情是1.认真锻炼身体，划分更多时间给锻炼2.认真按照私密文件夹里的视频学习体态和护肤3.在自由的时候保持作息4.拿到保研资格准备港科大phd\n对于掉头发这些哈哈哈，是在遭不住了就植发去，然后顺便把皮肤给修了。这些外在的是可以改变的，真正要修炼的是身体机能体态这些，以及内心修养。\n","date":"2020-12-31T19:52:23+08:00","image":"https://ercbunny.github.io/p/2020%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/2020_hu4961ff54ea972e84eb5ca448ce932c40_2786506_120x120_fill_q75_box_smart1.jpg","permalink":"https://ercbunny.github.io/p/2020%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","title":"2020年度总结"},{"content":" 主要工作 学分绩 大一摸清了一些考试规律，所以大二更加注重对知识的掌握程度，而非仅仅停留在把握整体框架上，于是在最后考试的时候做题不会感觉生疏。虽然有些课是真的不戳我兴趣点，但是还是硬着头皮去学了，毕竟抛开卷的问题，学分绩在哪里都是很重要的，所以丝毫不敢放松。\n最终结果是把均分从84.4拉到了88.0，只看第二学年的话均分有92.0，算是一个进步。本来的目标是上90就好，除了数电，其他都达到这个目标，于是我有些小得意，认为做到这已经足够了，但实际上还是没多少竞争力，所以接下来还需要向满分看齐才是。\n工训省赛 其实之前也没有特意向去参加这个比赛，但是因为它给了一个机会继续捣鼓捣鼓无人机，就索性参加了。我们基本试遍了各种可能的方式，对无人机现在的局限和未来的发展方向也有了更清楚的认识。主要局限还是在传感器融合和定位问题上面。\nRM2020 说起来比较惭愧，这个赛季我比较划水，做的都是些比较基础的工作。视觉部分代码沿用的是SJTU2019的框架，而使用的相机硬件上不一样，于是需要为我们选用的大恒相机写相机驱动代码。考虑到这部分工作比较简单，这工作就交给我了。这部分工作确实也比较简单，重新写了一份wrapper就结束了，所以后面又跟着把SJTU的整份代码过了一遍。之前一直不明白用C++到底应该怎么组织一个大项目，理清之后算是明白了。最终效果还不错，能够在480p分辨率下稳定达到60FPS以上，在低快门速度条件下大概能稳定在110FPS左右。具体记不太清了，但应该是比较顺滑的。\n准备UCB交换项目 有个同伴一起准备还是真的挺不错的。我们可以同步信息，一起练习口语之类的，所以准备过程还是非常轻松的。之前我20年元旦写道：如果不出意外的话再过一个学期就可以去交换了……然后果真出意外了，所以申请到之后与那边不断联系的过程是令人焦虑的，最后是再三推迟，一直推迟到了大四学年，到时候看自己更加清楚自己发展方向之后再决定去不去吧。\n 展望 接下来的学年是学分绩竞争的决赛圈了，学分很重，但幸好对几门课比较有兴趣，希望能保持上升之势。再有就是希望自己能尽早确定自己的方向叭。\n","date":"2020-06-01T18:52:23+08:00","image":"https://ercbunny.github.io/p/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4%E6%80%BB%E7%BB%93/grade2_hu65db3d3950f69fe59edc17a383b8c148_35066_120x120_fill_box_smart1_3.png","permalink":"https://ercbunny.github.io/p/%E5%A4%A7%E4%BA%8C%E5%AD%A6%E5%B9%B4%E6%80%BB%E7%BB%93/","title":"大二学年总结"},{"content":" 这是什么 在2020年初，我写下了一些对“‘主旋律’和生活本身协调问题，或者说怎么协调所谓正事和兴趣的问题”的一些思考，然后一直存在我的本地磁盘上，现在觉得可以放在个人主页上来充实一下内容\n正事是学业和事业，是直接和以后的成就高度和生活水平相关的硬核事务。这个东西如果要很深入可能要上升到人生意义和君之何从的哲学问题，很难回答，一般的做法是先着眼于当下的小目标，这个小目标就是所谓的主旋律或者说大方向。而兴趣以及生活可以看成是一个愿望清单，里面包括各种杂七杂八的愿望，等着自己去实现。\n这两者的关系应该是相辅相成，互相成就，而不能因为心中某种“我必须要这么做才能出成绩”的想法束缚了自己的行动，把自己的每一天限定死在那几个动作上，这里说的是思想包袱。如果每周都带着这种思想包袱安排生活，那多没有意思啊。有些心中的愿望可能错过了就来不及了。\n之前读到过John Goddard的愿望清单，真的很有启发。先把愿望列出来，再用各种方法在合适的时间把他实现，如果想都不敢想，那基本没有实现的可能了。这里打算仿照它列一份自己的愿望清单，会持续更新。\n关于人生的意义的思考：\n 每个人的归宿，就是自由。追寻本心的自由，做自己想做的事情，不用迎合什么，也不会委屈自己 “让自己快乐快乐这才叫做意义” 如果意义本身可以探寻的话，可以引申为“做自己想做的事，做能让自己满足和快乐的事情，凭自由意志决策和行动” “为其所欲，行其所想，唱自由向往”   My List 探险  珠穆朗玛峰 南极洲 北极 撒哈拉沙漠  学习文化  日本 韩国  造访  日本动漫巡礼 夏威夷 弗罗里达 加利福尼亚 新疆 欧洲各国 梵蒂冈 复活节岛 意大利 埃及 俄罗斯乘坐mig29  杂七杂八  学会驾驶汽车 学会驾驶各种飞行器 学会跳伞和翼装飞行 乘坐一次潜水艇 学习枪械和弓弩 攒一台史诗级主机 攒一架FPV飞翼 （2020.2完成） 在大学期间晚会上表演一次(2021/12/26完成) 取得世界公认的硕士（或以上）学位 成家立业(〃￣︶￣)人(￣︶￣〃)（此条随缘吧，不要太迫切希望） 尝试脱离地球母亲的怀抱 亲眼看一看22世纪的样子 在20周岁之前把肚子上的肉给减下去 （2020.4.8过期：有一定成效，还需继续努力） 在大学期间参加RM战队 （2020.3完成） 本科毕业前从PCB到软件自己写一套VTOL飞控（精力不允许，暂时不想设计硬件相关的东西） 护肤护肤护肤，做医美也不是不行 保存头发，实在不行了就去植发 认真学声乐，参加一次十佳歌手   The Rhythm Finish undergraduate school  认真做毕设 努力在自己的领域中学多点 抓紧时间enjoy college life 可以的话多读点经济运作/社会运作的书籍 是否应该在暑假去DJI实习（剑指offer66） 运动运动运动  Get a PhD/MPhil degree in the field of robotics (perception/control/planning)  可以的去处有  HKU/HKUST HITSZ/HIT SGP UZH ……   看清robotics领域全貌，毕竟目前还有东西没学会的，或者是去接触航天的一些项目 在自己的领域做出点贡献 认真想想以后可能会腾飞的行业，或者第一步gold mining做什么比较好 保持身体  Find a job and establish personal life in the world  先自立 看offer吧，可以做的应该有很多，但可能得花点时间刷题，相关的项目  DJI Apple/华为 米哈游/哔哩哔哩 进高校科研岗HIT/BUAA/西工大   获取资本可能的方法  第一种是老老实实上班，辛辛苦苦存钱 第二种是多几分辛苦兼职，强化加速存钱速度 第三种是借用人脉资源入股参与项目稳定赚钱 第四种是多学技能和工具，从小钱外快积累 第五种是背靠大树从免费帮助到升级为助理和兼职 第六种是稀缺信息壁垒，做个中介轻松赚钱 第七种是知识付费，做一个付费社群提供足够的服务和价值 第八种是朋友多+狗屎运，一不小心参与了个事儿就赚了 如果想用互联网，“那么起码需要掌握一门编程语言（PHP/Python/C#/Java都行），一种数据库以及基本的HTML/Javascript知识”    Try to get the first bucket of gold  努力学习投资知识，学着怎么管理资金，怎么用资金 对中国和世界的经济运作有一定的认知 找机会/风口果断入行，做出一番事业  Space/airline industries （based on 先前的基业）  希望自己真的能有机会开飞机上太空 space hotel/bar CSS support（和CNSA和军工达成合作关系，让毕业生不再为待遇不够而发愁） general airline RC fields space exploitation  ","date":"2020-01-01T15:45:12+08:00","image":"https://ercbunny.github.io/post/outlook/wishListCover.jpg","permalink":"https://ercbunny.github.io/p/%E6%84%BF%E6%9C%9B%E6%B8%85%E5%8D%95/","title":"愿望清单"},{"content":" 2019总结 这一年过得非常充实。\n课业上基本都是基础课，而且基础课要一直持续到大二结束。有意思的专业课都被学校放在了大三。大三得出去交换，要不然很难完成“取得世界公认的硕士（或以上）学位”这个目标呀。不过听说那边课也能选到对应的，而且怎么说呢，感觉在这边也是基本靠自学。学分绩上最终的结果是排名到前0.3，还混了个三等奖学金。\n运动方面，基本没怎么打球了主要是找不到合适的对手。所以基本上就是跑步和游泳。一开始都是断断续续的，到最后对锻炼更加看重了，所以好像貌似坚持的效果更好了一点。\n课外活动方面大概是三大块。第一块就是大一立项填坑。八月份的试飞调试真的还历历在目。第二块是工训比赛。为了做一个高级版无人机，我们基本试遍了各种可能的方式，对无人机现在的局限和未来的发展方向也有了更清楚的认识。最后一个板块大概就是RM视觉代码的编写吧。这个其实一直拖，拖到年末了才开始。不过总算是开始了，开始融入一个潜力爆炸的团队。吐槽一句大恒相机的SDK写得是真的差。\n 2020展望 根据课程大纲，春季学期理论力学、数电模电、电路基础、各种实验、数据结构和算法一起来，可算得上是枯燥硬课最多得一个学期了。提前做好心理准备也得硬抗。抗过这个学期，如果不出意外的话应该就要跑去伯克利交换了。到时候好好享受并且努力结识各路好汉，为Master学历做准备。\n当然了为了能够出去交换，大物和电路必须要考好！以及寒假要好好准备一下托福。闲下来时练练琴，整整FPV其实也不错。\n好啦好啦，就写到这里吧，再晚敲键盘得声音就要影响到舍友啦！拜拜ο(=•ω＜=)ρ⌒☆。\n","date":"2019-12-31T17:52:23+08:00","image":"https://ercbunny.github.io/p/2019%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/2019_hu0801e8d3e958bda0c56cce287f8c2963_265171_120x120_fill_q75_box_smart1.jpg","permalink":"https://ercbunny.github.io/p/2019%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","title":"2019年度总结"},{"content":" VIDEO DEMO \r\r SYSTEM OVERVIEW   VTOL is achieved by adding a mixing unit to the F4 flight controller running Betaflight Y3 firmware\n  The mixing unit takes in PWM outputs of a basic multicopter flight controller and yields signals for VTOL actuators\n  We only implemented attitude control. Communication between boards is via PWM\n   Illustration of the UAV | ①: Aileron, ②: Rudder \u0026amp; Elevator, ③ \u0026amp; ④: Tilt Servo, ⑤: Motor \n System Block Diagram \n Essential Part of the F1 Mixing Unit Explained \n DETAILED REPORT  View PDF (Chinese)   Contents of the detailed report are in Chinese as they were made originally to support the Chinese presentation. A rework and translation of illustrations, diagrams and the report is in progress, but don\u0026rsquo;t expect it to be finished soon. Best regards~\n ","date":"2019-08-15T13:20:21+08:00","image":"https://ercbunny.github.io/p/a-3-rotor-vtol-uav/cover_hu937dc71485028e8ffe6cb945e1660d91_2834993_120x120_fill_box_smart1_3.png","permalink":"https://ercbunny.github.io/p/a-3-rotor-vtol-uav/","title":"A 3-Rotor VTOL UAV"},{"content":" 摘要 此规划分三部分。第一部分是基于MBTI测试的自我分析；第二部分是未来一到两年的详细规划；第三部分是到毕业时的中期规划，主要谈谈感兴趣的方向和各种可能性。\n 基于MBTI测试的自我分析 测试结果：INTJ，Introverted Intuition with Thinking，追求能力与独立。\n适合的领域中我也比较中意的有：设计工程师，学者，科学家，技术顾问，系统分析师，项目开发部经理。\n此类人是完美主义者，倾向于严谨地，有逻辑地，有谋略地解决问题。他们在对自己感兴趣的问题上和自己形成的看法和计划上会投入很多注意力能量和积极性。\n气质类型结果是概念主义者，说我适合提供自由变化和需要较高脑力的工作，不喜欢简单重复的工作，擅长长远整体地把握问题等。\n这种测试的主观性很强，并且会让自己产生一种代入感。当然了，现在的自己完全还不具有测试结果中列出来的一系列优点。所以它大概反映了自己心目中理想的自己，大概展示了一下自己想成为怎样的人。那么好吧，朝着这个方向努力。\n而我现在大概只具备了在感兴趣的问题上非常热情的特性，用得好事半功倍，用得不好则拾小遗大，说不准这是优点还是缺点。至于其他的思维能力，要慢慢鞭策自己去习得。\n当然了，测试结果中也有一些弱点的描述，比如：给自己定了不切实际的高标准，喜欢逼迫别人像逼迫自己一样去工作，忽视一些社交问题而让人觉得冷漠等。那么这些潜在问题给我提供了一个我忽视了的东西，应引以为戒。\n 一到两年的短期规划 短期规划分两部分。第一部分是这个阶段内的目标；第二部分是为了达到这个目标日程应该如何规划。\n目标一：保证平时成绩。教务网标准学分绩底线是85，4.0标准的GPA底线是3.5。2019年3月24日星期日22：32截止，我的学分绩分别是83和3.42，主要是上学期课堂参与感差，过于注重收纳整理缺少练习运用造成的。换一种没那么功利的说法吧，那就是保证学习的质量，把每门课都学好，打下坚实的基础。毕竟对于很多课程我都是很感兴趣的。\n目标二：坚持运动。这个嘛，说来惭愧，主要还是觉得自己太胖了。20岁时应该是身体素质最棒的时候，如果腹部还是没有肌肉的话估计这辈子都别想有了。\n目标三：六级至少要考得比四级高。但是考虑到六级还是有一点难度的，那就追求稳630冲640好了。我英语的弱点在于翻译和写作，要有意识地多训练这方面。\n目标四：在Robocon或者是Robomaster中选一个并在里面提高自己的知识水平。怎么说呢，总感觉Robomaster的自由气息浓一点，更喜欢那里的氛围；但是之前又加入了Robocon管理组，还是得把自己工作做好。人们总说工程界是很关注团队合作的，参加这个应该很有好处。\n目标五：从第三部分中的大方向中选出一条并为之努力。\n为了达到这五条目标（实际上三四条就差不多了）制定了更具体的方法论。\n上课的时候要努力理解问题，不要想着什么都记下来就万事大吉。草稿和课本，一个做算例一个记下理解和补充内容。工作日的仔细要严格分配时间六点半到九点四十五，头十五分钟做英语，后面三个小时分别分配给高代物理和数分，不能拖时间按照入栈出栈的方式保存现场，方便下一次拾起。另外，课后习题每一道题都值得研究，不要总等到老师过来勾题做，自己每天都要一点一点做了。九点四十五回宿舍准备运动。跑步大概到十点四十回来洗漱。剩下还有时间用于MOOC立项或者通识课。周末要做的是对所学的知识进行复习并且整理、电子化。\n 中期规划 这里主要是写一下比较可能走的路。\n第一条是去哈工大或者北航甚至是一些面向航空或航天方向的研究所深造。这条路子比较对我的胃口吧，但是看到知乎上说体制僵化待遇偏低，就有点迷茫。\n第二条是去港科大或者阿咩利卡看看提高知识水平。港科大是不错的选择，最近也在看一些此学校优势，不过话说回来要是去港岛为啥不干脆去阿咩利卡闯一下呢……人工智能、机器人和自动控制都是很有趣的东西……\n总的来说，这个中期规划的时间段有点长了，现在大多数想法都很不成熟，仅作参考。但是也如上文的短期规划（实际上也不算短了吧）所说的，要尽早定下一条并为之努力。\n 最近看到一段话：“学术界也要交流，要申funding要social的，很多小朋友对学术界充满了各种臆想，感觉是报告文学读多了”。学术界尚且不是极端地埋头苦干，作为本科生，大概也不要太极端而失去了作为社会一分子的生存交际必要能力。\nWork hard, work smart and work together.\n ","date":"2019-03-27T11:07:12+08:00","image":"https://ercbunny.github.io/post/outlook/MBTICover.png","permalink":"https://ercbunny.github.io/p/%E5%9F%BA%E4%BA%8Embti%E7%9A%84%E8%81%8C%E4%B8%9A%E7%94%9F%E6%B6%AF%E8%A7%84%E5%88%92/","title":"基于MBTI的职业生涯规划"},{"content":" VIDEO DEMO \r\r DESIGN  Please refer to the related links   RELATED LINKS  百度贴吧 Source Code  ","date":"2018-09-14T10:19:16+08:00","image":"https://ercbunny.github.io/p/bunnyaat/cover_hu46c0689e392b8ce051806a075526a47c_6317262_120x120_fill_box_smart1_3.png","permalink":"https://ercbunny.github.io/p/bunnyaat/","title":"BunnyAAT"}]